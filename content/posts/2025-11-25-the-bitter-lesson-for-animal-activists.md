---
title: "The Bitter Lesson for Animal Activists"
date: 2025-11-25
substackUrl: "https://sandcastlesblog.substack.com/p/the-bitter-lesson-for-animal-activists"
draft: false
---

*A new generation is revolutionizing the grassroots animal movement, by learning the same way superintelligent AI learns.*

There are a lot of things about activism that I wish I had learned sooner. When I think back on my first five years as an activist, I’m not sure I helped a single animal. (Well, OK, there were about two dozen chickens I manually removed from factory farms, and I’m very happy for them, but I was aiming a lot higher.)

In my second five years, I think I came closer to maybe helping animals. I look back on it as a very slow pivot from *totally off course* to *kind of pointing in the right direction*. It was like steering a giant cruise ship. The thing is, I don’t think it had to be nearly that slow. I want to be a fast learner, because I want to help animals, and the longer I’m wrong, the less likely I am to do that.

This post is about the most important thing I’ve learned: how to learn. It’s about two different approaches to truth-seeking, especially as they apply to finding the best strategies for animal advocacy: *logic* and *empiricism.* In part 1, I’ll share stories from inside and outside the animal movement that helped me differentiate these two methods of learning. In part 2, we’ll meet a new generation of organizations who learned faster than me, bringing a long-overdue empirical renaissance to the grassroots wing of the movement. Finally, in part 3, we’ll gather up the key lessons about how to think and learn most effectively.

# Part 1: The Triumph of Empiricism

*“One experiment is worth a thousand expert opinions.” (Attribution unknown)*

Until recently, I always thought of *logic* and *empiricism* as close relatives, two sides of the same coin. They both belong to the domain of scientific, rational thought. *Logical* or *deductive* *reasoning* involves starting with first principles and reasoning forward to arrive at relevant conclusions, while *empirical* or *inductive reasoning* moves in the opposite direction, starting from observations and working backwards to distill patterns and rules. Both, I figured, are necessary for the scientific method; we start with empirical observations, work back to hypotheses about the laws giving rise to those phenomena, then reason forward logically to suppose about the as-yet unobserved consequences of those laws.

That story is partly true. But it turns out that logical and empirical approaches to truth-seeking are in tension more often than I once thought. Using logic to deduce the way of the world goes back all the way to Plato and Aristotle in the West and Confucius and Mencius in the East. Using logic, Aristotle reasoned that rocks fall faster than feathers because rocks come from the earth and feathers come from the sky, and each yearns to return to its natural place. He also deduced that slavery was the natural condition for some people, and that to deny as much was an affront to nature.

For nearly two millenia, people relied on their methods of logical deduction– or more often, simply appealed to the authority of their conclusions, placing these masters of antiquity on a pedestal few dared question. It took empirical observation finally elbowing its way into the truth-seeking process to set off the scientific revolution we are still living through today.

But not everyone has gotten on board. Conflicts between logical and empirical reasoning can be found lurking beneath disagreements at every level of society. Nothing brought this into focus for me quite like learning about the history of artificial intelligence.

## 1.1 The bitter lesson

Since Alan Turing first imagined machines thinking like humans in the 1950s, the field of artificial intelligence has been split into numerous camps, each with different theories about the best way to create thinking machines. These theories can be sorted into two broad categories: the **logicians,** and the **empiricists.[^1]**

Logicians believed that the way to build a digital intelligence was from the ground up. Some hoped to program a hyper-logical brain by coding in, line-by-line, an understanding of the rules that govern the universe. Others sought to completely deconstruct the workings of the human brain and recreate them in a digital copy.

Perhaps the most ambitious deductive effort was made by Douglas Lenat. In 1984, he left a post researching AI at Stanford to launch a project codifying the entirety of human common sense into a form that could be understood by computers. His team set out manually encoding logical assertions like “All trees are plants,” “People eat food,” or “You can’t be in two places at once.” Every concept was given a formal definition comprised of its logical relations to others, reflecting his belief that words are given meaning in human minds by their connection to other words in a vast network of implicit logical rules like these. But Lenat underestimated just how vast and nuanced that network is. After spending three decades toiling away writing millions upon millions of rules, Lenat was forced to admit that “We’re still nowhere near having codified all the everyday knowledge a person needs to read a newspaper or watch a movie.”

Deductive approaches like this were daunting from the beginning. But inductive approaches seemed even more desperate. Empiricists believed that the way to build digital intelligence was not to build it at all, instead letting it learn on its own. They thought the interesting lesson of the human brain was not how it happens to be structured, but how it learns and the evolutionary process that gave rise to it. Early empiricists imagined a simple learning algorithm as blank and malleable as a human infant observing the world, testing things out, and constantly rewiring its brain through trial and error.

There was just one problem: that’s not how computers worked. For one, you couldn’t get experiential data into them. They didn’t have eyes to see with or hands to try picking things up, and in the 80s, there was no digital world for them to adventure around in instead. Even if you could get data for them to study, actually learning from data seemed to present a paradoxical bootstrapping problem; without some initial logical rules, computers couldn’t begin to make sense of new information enough to learn from it. But if you tried writing rules, you quickly ran into the endless complexity that doomed Lenat’s project.

The first efforts at building an AI *inductively* floundered. Deductive efforts were floundering too, but through the end of the 20th century, they seemed more promising, and most AI researchers were focused on figuring out how to distill down the common sense rules humans use to navigate the world into something as simple as they seem, subjectively, to us. Empiricists were marginalized within the AI field.

Two things changed. The first was **better computers.** Moore’s Law, the observation that leading edge computer chips tend to double in processing power roughly every two years, meant that between 1965 and 2005, the per-dollar performance of computer chips increased more than a billion-fold. Unsurprisingly, having a billion times as much computing power enables you to do things you couldn’t do before. In the early 2000s, a new set of learning methods designed to take advantage of all this newly available compute started to outperform deductive computer programs in areas like natural language processing and speech recognition.

The second change was **more data.** The emergence of the internet gave AI researchers access to sheer volumes of data that were unthinkable a few decades earlier, including sound and video. More than that, the internet created a whole new digital world in parallel to the physical world, one where learning algorithms could go out and fumble around the way babies do. Video games proved to be an especially fruitful environment for AI learning experiments during the 2010s.

With better computers and more data, empiricism attracted new attention, and soon, empiricists were getting equal billing with logicians at AI conferences. In 2015, Pedro Domingos, a leading researcher in AI, published a provocative book called *The Master Algorithm* in which he argued that the key to AI was combining the special insights of all the different schools of research, the different inductive and deductive techniques, into a hybrid approach.

Reader, he was wrong.

Just a few years later, one approach to AI had left all others completely in its dust. This approach, called *deep learning,* was the most militantly empirical of them all. Deep learning minimized human assumptions about how intelligence should work, relying instead on a simple, naive algorithm using vast data and compute to discover structure on its own. A pure deep learning algorithm starts without a single precoded assumption from its creators about how to win. It is simply given a definition of success and then told to try and fail until it figures it out. In the case of LLMs like ChatGPT, winning is predicting the next word on a web page, but deep learning can also be applied to winning a game of chess or inferring the next sound in a music file.

![](https://substack-post-media.s3.amazonaws.com/public/images/cd0aca8b-6004-4b38-9412-4400e6574aa7_1536x1024.png)

*Swallowing the bitter lesson…*

For many AI researchers who had poured decades into attempts to formalize logic and common sense, the triumph of deep learning was heartbreaking, or even repulsive. AI researcher Richard Sutton summarized this in a short 2019 letter to his colleagues called *[The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html):*

> The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin… Seeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation.
>
> In computer chess, the methods that defeated the world champion, Kasparov, in 1997, were based on massive, deep search. At the time, this was looked upon with dismay by the majority of computer-chess researchers who had pursued methods that leveraged human understanding of the special structure of chess. When a simpler, search-based approach with special hardware and software proved vastly more effective, these human-knowledge-based chess researchers were not good losers. They said that “brute force” search may have won this time, but it was not a general strategy, and anyway it was not how people played chess. These researchers wanted methods based on human input to win and were disappointed when they did not.
>
> …
>
> We have to learn the bitter lesson that building in how we think we think does not work in the long run… the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries. All these are part of the arbitrary, intrinsically-complex, outside world. They are not what should be built in, as their complexity is endless; instead we should build in only the meta-methods that can find and capture this arbitrary complexity. Essential to these methods is that they can find good approximations, but the search for them should be by our methods, not by us. We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.

Once enough computing power and data became available, inductive/empirical approaches to building AI completely obliterated deductive/logical approaches. This triumph of empiricism over logic has implications far beyond the field of machine learning, however. The study of artificial intelligence is the study of all intelligence, because to create an intelligent mind, you must first understand something about what intelligence is or how it arises. Since the beginning, some researchers have been interested in AI because of the potential to build superintelligent systems that can do things humans cannot do. But others have been drawn to the field by the promise of learning about what human intelligence is and how it works.

Creating AI has taught us more than centuries of philosophy about what learning and knowledge are, how they work, and how to do them more effectively. One of the most important and general lessons is that **empiricism is a superior approach to truth-seeking**.

## 1.2 The empirical/logical divide in animal advocacy

When Sutton describes some researchers refusing to accept the bitter lesson that their preferred approach was not winning, I recognize a younger version of myself. My goal, of course, was not building AI, but achieving animal liberation, first as an organizer with Direct Action Everywhere.

When I got involved in the animal movement, big changes were afoot. In 2005, a massive campaign to shut down an animal testing company, the Stop Huntingdon Animal Cruelty or SHAC campaign, had ended with a harsh federal crackdown in both the U.S. and UK that had an acute chilling effect on animal activism. For a decade after the [SHAC prosecutions](https://en.wikipedia.org/wiki/Stop_Huntingdon_Animal_Cruelty), the remnants of the movement had been focused on two strategies. One was a smattering of disparate local pressure campaigns targeting anything from rodeos to fast food chains, with protests often involving nudity and fake blood. The other was vegan leafleting.[^2] For the most part, well-funded professional groups and local, all-volunteer grassroots groups alike were focused on these same interventions.

By around 2014, both of these approaches were being seriously questioned (more on why in a future post) and a new strategic division was emerging.

### The empiricists

One side was driven by the arrival of Effective Altruism to the animal movement. EAs were committed to using rigorous quantitative analysis to evaluate charitable interventions according to how much they improved lives per dollar spent. Effective Altruism was a young movement that had first made its mark challenging the orthodoxies of charities working to reduce poverty in the developing world. In a few years, EA-aligned researchers had shaken up a charitable sector more concerned with photo ops and heartwarming stories than measurable results, demonstrating that a few neglected interventions (especially malaria nets and direct cash transfer) were *hundreds or thousands of times* more effective per dollar than trendier aid programs.

When EAs turned this rigorous, empirical lens on animal advocacy, they found similarly lopsided results. (They also found controversy– more on that in a moment.) Most of the campaigns animal advocates were running involved putting disproportionate amounts of energy into issues that affected only a small number of animals, like rodeos and circuses. Often, these campaigns could only succeed if the target of the protest went out of business entirely– it’s not easy to cause someone so much inconvenience that they will shut down their profitable business. Meanwhile, early studies claiming that vegan leafleting was amazingly cost-effective were shown to be badly flawed, and new studies made these diet-change efforts appear hopeless.

But there was one diamond in the rough. When EAs analysed the cost-effectiveness of everything animal advocates had been doing, a certain type of pressure campaign jumped out. Unlike other campaigns, these were resulting in wins, often with surprisingly little effort. And these wins were affecting the lives of more animals than even the organizers of the campaigns had realized.

These were corporate welfare campaigns. In hindsight, it’s easy to see why corporate welfare campaigns were so promising. First, they targeted consumer-facing companies like fast food chains, which were sensitive to their brand image. (As a comparison, the SHAC campaign mentioned earlier was targeting an obscure biotech company that didn’t care much about public opinion.) Second, they focused on incremental welfare reforms that made at least some difference in animals’ lives while only trivially impacting the businesses’ bottom lines. (Again contrasting with SHAC, which sought to completely drive their target out of business.) As a result, welfare campaigners had racked up a string of wins by 2014, compelling some major food companies to source cage-free eggs. Sometimes just one or two protests was enough to get a commitment from a new target.

Using the lens of cost efficacy, EAs looked at vegan outreach, impotent protests outside rodeos, and corporate campaigns, and once again saw a staggering asymmetry, with one intervention achieving thousands of times as much real-world change for animals as all the rest. Open Philanthropy, the foundation driving much of the EA movement, sent out word that funding was available to any organization able to turn money into victorious corporate welfare campaigns.

### The logicians

But not everyone was happy about cage-free campaigns. To some activists, especially many volunteers on the grassroots side of the movement, welfare campaigns represented too much of a departure from the message that animals have a *right not to be exploited*. We also saw the EA style of quantitative analysis as overly reductive. Sure, that works fine in global poverty alleviation, where everyone agrees what the goal is and it’s just a question of how to get there. But the animal movement is a fringe cause fighting against a deeply entrenched social norm. We argued that our strategic environment was more complicated and nonlinear.

Grassroots abolitionist leaders like Anita Krajnc (founder of the Save Movement in 2011) Wayne Hsiung (founder of Direct Action Everywhere in 2013) agreed that vegan leafleting and sporadic rodeo protests weren’t working. But where the EAs looked at the recent experiences of animal advocates to see what was working, Anita, Wayne, and others wanted to dream bigger.

Nobody in the animal movement had ever achieved what they were trying to achieve– a revolution in social attitudes, ending the property status of animals. But while animal advocates hadn’t achieved this, other movements had. The abolition of slavery, women’s suffrage, the civil rights and gay rights movements all represented successful historical analogs for what we were doing.

DxE and the Save Movement studied the history of social justice movements and distilled a set of principles or laws about how small groups can spark transformational social change. For instance, DxE frequently cited the work of one scholar of political revolutions, Erica Chenoweth, who found that no revolution failed once it activated 3.5% of the population into sustained civil disobedience. Based on that, we devised a strategy focused on mobilizing more and more people into the movement until we could trigger an Occupy Wall Street-style mass protest event for animals.

This might not sound so different from what the EAs did with corporate welfare campaigns. Both camps were looking at evidence of what worked; we were just looking at different evidence from different times, and drawing different conclusions. Both reflected an empirical, observation-based approach, merely disagreeing about which evidence was most valuable and what the goal should be.

### Historical evidence & falsification

At least, that’s what I thought at the time. When I first got involved in the movement, DxE’s approach was far and away the most appealing to me. I wanted us to aim high, and it made sense to me to draw on historical evidence of other successful movements. Wayne and Anita both cited ample scholarship to support their theories of change; the scientific language appealed to me as much as the ambition.

Over the years, though, a gap grew between the EA corporate campaigners and the grassroots abolitionists. It maps surprisingly well to the camps in artificial intelligence research. One was agile, continuously evolving their strategy in response to feedback from the world. This camp demonstrated what I would call *disciplined thinking:* critically evaluating their most dearly-held beliefs in light of new evidence. Many of the organizations that eventually focused on cage-free campaigns had originally been organized primarily around vegan leafleting, but when the bitter news came undermining the evidence in favor of leafleting, they accepted it and changed course. The other camp, the one I was in, clung more and more tightly to our ideas about how winning *should* work. We failed to discipline our thinking. As a result, only one side delivered tangible results for animals.

The seeds of undisciplined thinking may have been inherent to DxE’s theory of change. While the EAs were focused on changing corporate policies in the short term, groups like DxE and the Save Movement were trying to win over the hearts and minds of the public. DxE in particular believed that using controversy to attract attention to the issue would generate *positive polarization.* Essentially, the moral worthiness of our cause was so self-evident, the main problem was that people were ignoring the issue altogether. If we could force them to confront it, eventually they would come over to our side. In the meantime, hostile reactions from bystanders and social media commenters (not to mention law enforcement) were only to be expected.

From a learning standpoint, the problem with this strategy is that it was *unfalsifiable,* at least in the short term. There was no empirical observation we expected to see within the first several years of pursuing this approach that would tell us whether or not it was working. This doesn’t inherently mean DxE’s theory of change was incorrect. But it doesn’t mean it was correct, either. It means we were flying blind, with no way to learn and course correct.

The only way to sustain our enthusiasm for this unverifiable strategy was to adopt an almost pathological overconfidence in the historical analysis behind it. This can’t be blamed entirely on the leaders. In fact, as so often happens in intellectual movements, the early adopters held more dogmatically to the founding ideas than the founders themselves. I was certainly more dogmatic about elements of DxE’s theory of change than Wayne was, and I opposed more than one proposal from Wayne to pivot the organization’s strategy.

Our approach was ruled by deductive logic, rather than inductive observation. That’s a dangerous place to be when it comes to historical evidence, because it’s so easy for us to project our pre-existing beliefs onto these stories. I once [put a question about this to Lewis Bollard](https://forum.effectivealtruism.org/posts/ymsgPwLh9agzpsbKe/?commentId=EKjebx3GnB6Gxditn), the director of the farmed animal grant program at Open Philanthropy. His short answer stuck with me and significantly shook some of my old convictions about history:

> *I asked:* Looking at major changes societies have adopted in the past, the path to these changes has often been nonlinear. A frequently-discussed example is the U.S. civil rights movement, where the extent of violent opposition reached a near zenith just before the movement’s largest victories in the 1950s and 60s. Gay marriage in the U.S. was another example: in a 15-year period ending three years before marriage equality was decided by SCOTUS, advocates watched a wave of anti-gay marriage state constitutional amendments succeed at the ballot 30-1. Women’s suffrage, the New Deal, and (most extremely) the abolition of slavery were all immediately preceded by enormous levels of opposition and social strife. How does OP account for the nonlinearity of major societal changes when deciding what interventions to support on behalf of farmed animals?
>
> *Lewis answered:* I studied historic social movements in college and it’s been my hobby since, and it’s left me wary of extracting general lessons from past movements, since I think they often fit our prior beliefs. For instance, I see in the US civil rights movement a movement that for decades clocked up small achievable incremental legal and political wins in service of several larger incremental wins (two key federal laws and several Supreme Court rulings) but that failed in its more radical goals (racial and economic equality). I see in gay marriage a movement that largely sidelined radical calls to end marriage and other oppressive institutions in favor of a disciplined focus on a quite narrow practical goal: marriage equality. And I see the US abolitionists’ radical goals and tactics as largely a failure alongside the UK abolitionists’ more moderate ones, which achieved abolition decades earlier and without a war. But I suspect this is largely me projecting my beliefs on the past… **I’ve seen cage-free campaigns build public momentum, activist morale, and support for political reforms.** But I agree it’s likely we’re missing important work to seed future nonlinear reforms. I just find it hard to work out what that work is.

Activists who look to movement history to inform their current strategy are typically hoping to find constants, rules that apply across the different movements they study that explain why all of them were successful. But I’ve come to believe that the similarities between past movements are overrated. The real success story of each movement is the unique ways they learn to navigate profoundly dissimilar contexts and develop a strategy that fits their situation. As someone once said, the reason the Greeks were great was that they weren’t imitating anyone else. Romanticising the movements of the past as having tapped into some deep truth about social change is the same mistake as thinking that ancient thinkers like Plato and Confucius reached the limit of philosophy, rather than assuming that each generation should be able to build on the work of its predecessors to come up with something even better. Or, for that matter, recognizing that a constantly changing world requires new morals and new strategies.

# Part 2: The Empirical Renaissance

*“It’s OK to be wrong; it’s unforgivable to stay wrong.” – Martin Zweig*

The decade after the SHAC prosecutions represented a winter for animal advocacy. Winter’s thaw brought new energy to the movement. Effective Altruism disciplined the professional side of the movement, ultimately bringing behemoth multinational corporations to the negotiating table and leading to by far the most consequential victories animal advocates have ever achieved.

The renaissance on the grassroots side did lead to a period of vitality and growth, but ultimately, it failed to create disciplined thinking. Ten years later, however, the grassroots movement is finally due for its own empirical revolution. The movement taking shape today is less dogmatic and more agile than ever. Let’s take a closer look at four organizations in particular that embody this approach, and what other advocates can learn from them.

## 2.1 Animal Rising

In 2018, the UN Intergovernmental Panel on Climate Change released a report concluding that the world had just 12 years to change course in order to avoid the worst impacts of catastrophic climate change. The report came out just in time to supercharge a new climate-focused protest organization in the UK called Extinction Rebellion (XR for short). XR’s goal was to raise the level of urgency with which politicians, journalists, and the public talked about the climate crisis, and within their first few months, they had tremendous success, mobilizing thousands of ordinary British citizens to get arrested in colorful acts of nonviolent civil disobedience and attracting outstanding media coverage.

As usual, both climate activists and the media were talking about fossil fuels and neglecting the role of animal agriculture. A few animal activists recognized an opportunity to ride on XR’s coattails and ensure some of the media coverage discussed factory farming. They launched Animal Rebellion, calling animal activists to join XR’s next big mobilization, where they occupied London’s largest meat market and steered the narrative towards animal agriculture.

Whereas DxE had been formed around a deeply reasoned-out, long-term theory of change, Animal Rebellion was quickly thrown together to grab an ephemeral opportunity. And sure enough, that opportunity evaporated less than a year after the group launched, when the Covid pandemic put a halt to public protests. Yet in the long run, this turned out to AR’s advantage.

With XR no longer presenting an easy way to grab media coverage for the animal movement, Animal Rebellion was forced to execute their first big strategic pivot as an organization before they turned even one year old, figuring out *something* else to do instead. This turned out to be the first of many. In the five years since, AR has pivoted so many times that even close associates can find it exasperating (one of those pivots included rebranding the org to Animal Rising.) Here are a few of the disparate campaigns that AR has started over the years, then dropped without achieving any concessions from the target:

-   An anti-dairy campaign where activists went into grocery stores and repeatedly poured cartons of milk onto the floor, while others sabotaged a distribution center by drilling into the tires of tanker trucks, causing £100,000s in damages.

-   A campaign to temporarily shut down entire fast food chains by blockading a few key distribution centers.

-   A series of disruptions aimed at the top horse racing tournaments, with activists rushing onto the track to halt the races.

-   An investigation and rescue campaign at a major breeding farm for beagles used in scientific research.

-   A campaign against the RSPCA demanding that they drop a welfare labeling scheme for factory farms.


AR has faced criticism for bouncing around from strategy to strategy too quickly. It makes sense that people have this impression, but I believe the criticism is misplaced. In the five years I spent with DxE, we only made one strategic pivot as big as any of these. The result is that AR has experimented across a much wider range of possible strategies to find out what works. Those includes several orphaned campaigns that were abandoned after people spent countless hours and racked up criminal charges, but it also includes what I now consider some of the most exciting projects in the entire animal movement:

-   **Plant-Based Unis:** In 2021, AR student groups at three UK universities launched campaigns to demand their administrations transition to 100% plant-based food. Within a year, it spread to 20 schools and racked up [several impressive victories](https://www.theguardian.com/education/2023/feb/21/cambridge-university-students-vote-for-completely-vegan-menus)**.** The Plant-Based Unis campaign now trains student campaigners from hundreds of schools each year and is on track to have a campaign in every university in Europe. PBU also inspired similar viral campaigns targeting local councils and primary schools.

-   **Communities Against Factory Farms:** after organizing to block the building permit for a new factory farm by filing environmental objections with the local government, AR realized they’d found another scalable strategy. Their first four attempts to lobby local councils against approving permits were successful, suddenly contesting what had historically been a nearly automatic process of new factory farms being approved. They’re now aiming to scale the campaign up to contest every factory farm permit in the UK.

-   **Vegans Support the Farmers:** after working for years in the background to build genuine relationships with small and medium farmers, AR is now coordinating with Save British Farming on a lobbying campaign to stop the UK from accepting a trade deal that would open the country to low-welfare meat imports from the U.S.


Animal Rising’s rapid search across a wide space of possible strategies reminds me of a machine learning algorithm playing chess. Algorithms that made use of lots of computing power to try many different strategies performed better than those that thought hard about logical strategic rules coded into them by their programmers. Experimentation has had similarly fruitful results for Animal Rising.

Activist orgs should be less afraid of trying lots of different strategies, and less afraid of giving up when it becomes clear one of them isn’t working out.

## 2.2 The CAFT/AAC/ICAW coalition

When I think back to my first years in the movement and the ways that my brain worked, there are two things that most make me cringe. One is how fiercely I opposed cage-free and other welfare campaigns. I believed that cage-free was a moral betrayal of animals, and I also thought it was setting the movement back by making the general public feel better about animal exploitation. Both of those views were coherent and defensible at the time, and I’ll share another post soon about what changed my mind. But I was so opposed to these campaigns that I couldn’t admit being in a cage-free farm was even *slightly* better for hens than being in a battery cage. In hindsight, I consider that a totally ridiculous position that demonstrates how dogmatic and undisciplined my thinking was.

My second, related regret is that I categorically dismissed the importance of incremental wins. DxE protested in restaurants and grocery stores, but we didn’t have any demand for the targets of our protests other than to completely stop selling animal products. The point wasn’t to win a demand, but to shock the public out of their complacent acceptance of animal cruelty. I thought that having specific, winnable campaign demands attached to our protests would just force us to water down our messaging and distract from our goal of sparking a wider social transformation.

These views were not uncommon in the grassroots ten years ago. And there is no better demonstration of how much has changed than the recently formed coalition between Animal Activist Collective (AAC), the International Council for Animal Welfare (ICAW), and the Coalition to Abolish the Fur Trade (CAFT). Because that’s a lot of words and letters, from here on I’ll just refer to them as *the coalition*.

I wrote a few weeks ago about the [pointless divide between “grassroots” and “professional” organizations](https://sandcastlesblog.substack.com/p/my-grassroots-identity-crisis?r=6b0gzd) in animal advocacy. That division is one more thing the coalition has smashed through. It’s a marriage between two groups that come from the traditional “grassroots” wing and one from the “professional” wing, and while that enables them each to bring different skills to the table, the most important thing is what they all have in common: they love to win.

AAC started out a few years ago as Animal Activism Mentorship, a platform for experienced activists from across all different grassroots organizations to sign up to mentor new activists. To give mentees more opportunities for hands-on experience, they started hosting in-person convergences, then started organizing their own pressure campaigns, with a focus on foie gras. By filling a badly needed role welcoming new activists to the movement, AAC earned the deep trust and respect of the grassroots, and now they can turn out more activists than anyone in the U.S.

ICAW grew out of a very different part of the movement. It is made up of corporate welfare campaigners who felt that long-established welfare campaigning organizations had grown too cautious and bureaucratic. ICAW combines experience negotiating in the boardrooms of multinational corporations with willingness to punch hard when those negotiations break down.

Finally, CAFT has been cutting their teeth for years running relentless, laser-focused campaigns against luxury brands to adopt fur-free policies. They’ve perfected the research and strategic skills needed to win big campaigns as fast as possible, and they’ve racked up dozens of wins in just a few years.

This year, AAC, ICAW, and CAFT started pooling their skills and resources together to supercharge each other’s campaigns. AAC brings the activists, ICAW brings EA-aligned funding, and all three groups bring diverse expertise in pressure campaigning. This is only possible because the leaders of each group have sent a clear message: *we are done with the ideological disputes of the last decade. All of us are here to win campaigns that help animals, whether for “abolitionist” demands like ending fur and foie gras or “welfarist” demands like cage-free eggs and stunning shrimps before slaughter.*

The coalition embodies the spirit of empirical learning by running tons of concrete campaigns with clear, measurable win conditions. This reflects another key lesson from machine learning, known as *reward density.* Reward density is one of the most important factors determining which skills AI systems have learned to excel in and which they still can’t grasp.

**Empirical learning is about shortening the loop between trial and feedback.** You can try lots of approaches, but if you don’t get clear information back about which ones were effective, your experiments are useless. The faster you get feedback, the faster you can learn. In machine learning, the positive feedback given to a learning system for a task accomplished successfully is called a *reward.*

It’s nearly impossible to learn a skill if the rewards for successful trials are too sparse. Predicting the next word in a document is an effective training method because the system can check immediately if it was correct. How could you apply this approach to learning complex, real-world skills like running a successful business or, more relevantly, sparking a social transformation? You’d have to break that larger process down into lots of small, verifiable steps.

This alone is a reason to strongly prefer strategies that offer incremental wins: each possible win is a chance to test and iterate your approach. If your efforts don’t have any concrete observable outcome in the short term, there’s nothing to learn from or ensure you’re still on course. To this day, nobody knows for sure if DxE’s original theory of change was correct. Maybe we just needed to stay the course for another 10 years and we’d have started seeing measurable returns. That uncertainty was a difficult thing to build a movement around, and the fiery momentum of the AAC/ICAW/CAFT coalition proves that you might as well build a movement around genuinely impactful incremental wins instead.

## 2.3 We The Free

DxE wasn’t the only grassroots activist organization in the 2010s weighed down by dogmatic thinking. Even more rigid was Anonymous for the Voiceless. In many ways, rigidity was AV’s greatest strength. AV did for animal activism what Henry Ford did for manufacturing. They were laser focused on organizing street outreach events. Activists used screens showing slaughterhouse footage to draw people into live personal conversations about veganism and animal rights. They had these events down to a science: what footage to use, what music to play, even what clothes you were allowed to wear were all prescribed by the central organization.

This made it fantastically easy for a new organizer to start an AV chapter in their city; there were hardly any decisions to make. This made AV spread like wildfire, and they were responsible for more new animal activists than DxE and Save combined. But rigidity had serious drawbacks. As organizers gained experience, there was no opportunity for them to express their own creativity or adapt the AV model to their local setting based on what they were seeing on the ground. Experimentation and learning were effectively banned across the network. Some AV organizers I knew were secretly breaking the rules in order to make the model fit with their unique cultural context, but most just grew more and more frustrated with the rigid control until they left the organization altogether.

Fortunately, the world is a big place, and when you find you can’t experiment inside of an organization, there’s a vast blue ocean out there. We The Free was launched by a few long-time AV organizers who still believed in the power of vegan street outreach, but wanted the space to experiment, learn, and improve. Starting in 2021, they organized local chapters around almost the exact same style of AV, with one difference: experimenting with changes wasn’t just allowed, it was encouraged. Former AV organizers flocked to WTF, bursting with ideas they had been forced to keep to themselves for years.

Within a year, WTF’s standard approach to activism had transformed so much it was barely recognizable. This evolution drives home a recurring theme: proper experimentation requires not just trying new things, but *measuring the results.* From day one, WTF were obsessed with data. Every activist who attends an event is given a custom link to hand out to people they outreach. As a result, the central organization can track the numerical performance of every activist, at every shift, in every city. This is the kind of data that supercharges learning for people, machines, and organizations alike. We The Free’s continuously evolving approach to activism is based not on logic or hunches, but on empirical data about what is working, from the global level down to the local level.

## 2.4 Pro-Animal Future

Street outreach has a high reward density, with dozens of possible wins at each event. Pressure campaigns are much slower, with each campaign often lasting months. But one area of advocacy is the most infamously difficult to subject to empirical learning methods: politics. That is the challenge faced by Pro-Animal Future (which, full disclosure, I co-founded in 2023.)

Elections in the U.S. only happen once every two years, severely limiting how quickly we can learn more effective ways to campaign for ballot initiatives and pro-animal political candidates. On the legislative side, a certain bill can only be proposed once per year at most, and bills often ride or die based on arbitrary factors that seem beyond our control.

To address this challenge, we tried to deconstruct pro-animal political campaigns into measurable parts. For two years before launching Pro-Animal Future, my cofounder Eva Hamer and I carried out experimental research on everything from messaging strategy to volunteer retention. Before we asked donors and activists to pour 1,000s of hours and 100,000s of dollars into a campaign, we wanted to ensure we were basing our strategy on as much up-to-date feedback from the real world as we could get.

When we finally launched our first ballot initiatives, we did everything we could think of to treat them as a continuation of this experimental approach. We gathered all the quantitative data we could on voter outreach efforts and ad performance. But our biggest and hardest lessons were more qualitative, insights about the particular ins and outs of politicking that caused us to rewrite our entire strategy. I’ve [written those lessons up elsewhere](https://animalcharityevaluators.org/blog/lessons-from-a-new-wave-of-pro-animal-ballot-initiatives/) so I won’t get into the details here. The important takeaway is: **even if you can’t collect relevant quantitative data, an experimental, empirical attitude goes a long way.**

You could undertake the same campaign in the same manner, with one of two attitudes. You could think, *this is the necessary approach, the path to victory. Never give up!* Or, you could think, *I don’t know the way. This is my next attempt to discover it. It may or may not work, but if I evaluate the process and outcome rigorously, I will at least come a big step closer to knowing how ultimate victory will be achieved!*

Together, these organizations represent a mature grassroots movement that has embraced empiricism. I’m sure there are other great organizations I’ve left out, especially outside the anglophone world, of which I ask you to forgive my ignorance.

# Part 3: Learning like a superintelligence

*“Those who cannot change their minds cannot change anything.” – George Bernard Shaw*

## Insist on winning

So far, we’ve set up the contrast between logic and empiricism; we’ve seen how it played out in the field of machine learning, providing a validated proof of the power of empirical learning; and we’ve examined how the same dynamics have underpinned different approaches to animal activism. For the rest of this essay, I want to discuss some of the foundations of the *disciplined thinking* that I see demonstrated by successful empiricists across different fields.

During my early years in the movement, I was so sure that my team had derived the correct principles for good social movement strategy. When I think back on that time, I recognize that I was engaging in undisciplined thinking that led me to (probably) faulty conclusions.

What do I mean by disciplined and undisciplined thinking? You probably have some idea of what I’m pointing too. There are various facets or ways we could refer to it, and I’ll recruit several more of them in a moment, but I like to use *discipline* as the umbrella term. To me, *discipline* conjures an image of someone who knows what their goals are, knows what it will take to achieve them, and has the determination to do those things even when it’s hard or they don’t want to. Discipline is the quality that enables a person training for a triathlon to hear their alarm go off in the morning and summon up the grit to drag themselves out of bed for an early run before work, day after day, even when that is the last thing they want to do. The one who lacks discipline will snooze the alarm, skip the run, and fail to complete the race when the big day comes.

Our goal as animal activists is to devise winning strategies. **Disciplined thinking is thinking that insists on achieving that goal.** It takes discipline because it requires us to question both dearly held beliefs and unconscious assumptions. We might not question dearly held beliefs because doing so threatens our identity, or threatens to destroy our sense of hope. We might not question unconscious assumptions because it takes a diligent effort to even notice them, and it’s easier to be lazy instead. The disciplined activist is the one who remains constantly focused on the goal and insists on organizing their thoughts in whatever way will achieve the goal.

## 3.1 Real thinking and fake thinking

Let’s get more specific. In a recent essay *[Fake thinking and real thinking](https://joecarlsmith.com/2025/01/28/fake-thinking-and-real-thinking#1-introduction),* Joe Carlsmith of Open Philanthropy identifies five overlapping dimensions of disciplined thinking. We could come up with more, but I think these are a great start. For each dimension, try to recognize examples from your own life where you practice disciplined or real thinking, and where you practice undisciplined or fake thinking.

1.  **Map vs territory:** Our brain creates shortcuts and generalizations about the world in order to avoid being overwhelmed by complexity. It would be impossible not to do this, but we must never forget that these generalizations are crude maps of the territory, not the territory itself. An example of a map is *social movements.* We use this term to draw an analogy between different clusters of historical events we call *the civil rights movement,* *the gay rights movement,* etc. But in a very important sense, there is no such thing as a social movement outside your mind. Even each individual example is not, in reality, a single thing. The *civil rights movement* does not have a discrete start and end date; it’s no more than analogy clustering together a set of smaller events, and no two people would agree on exactly which events to include. Maps are a useful shorthand, but when the time comes for real thinking, it’s crucial to direct your mind past these abstractions to focus on the real world lurking behind them. The animal movement is its own historical phenomenon and must be discovered anew.

2.  **Rote vs. new:** when you encounter a challenge, are you just sorting it into a pre-existing categorical schema in your head, or are you newly evaluating it on its own terms? We can’t do new thinking all the time– we make thousands of repetitive decisions every day using rote thinking. But we can make sure not to use that style of thinking for important strategic decisions. As an example, we’re all familiar with the long-running debate among animal activists over abolitionist vs welfarist demands. Many activists have thought through this question and reached a conclusion about where they stand, without noticing they continue to process new questions through that old conclusion even when they don’t fit. For example, I’ve met many activists who are skeptical of cage-free campaigns due to concerns about welfarism, yet are enthusiastic about campaigning against foie gras on the basis of force-feeding. Battery cages and force-feeding are both discrete practices that make animals’ lives worse, but banning them doesn’t remove animals from the system. Sorting foie gras into the ‘abolitionist demand’ category just because we describe it as banning a product is an example of rote thinking.

3.  **Soldier vs. scout:** this distinction was introduced by Julia Galef in her book *The Scout Mindset.* In strategic discussions, are you focused on defending a favored position, like a loyal soldier? Or are you able to embody the mindset of a scout, whose only commitment is to uncovering the truth? This one corresponds most closely to logical vs empirical thinking. Loyalty to a cherished, logically coherent belief or faction is one of the most common sources of undisciplined thinking. The logic-based AI researchers who refused to accept Sutton’s bitter lesson despite overwhelming evidence were guilty of the soldier mindset.

4.  **Hollow vs. solid:** if you earnestly commit yourself, you will start to notice what it feels like internally when you are engaging in disciplined vs undisciplined thinking. There’s a real difference. This pair and the next pair rely on that self awareness. Carlsmith describes hollow vs solid as: “Am I using concepts/premises/frames that I secretly suspect are bullshit, or do I expect them to point at basically real stuff, even if imperfectly?” For Carlsmith, sometimes it’s enough to “try stamping my foot (not always literally) and saying *no bullshit!*...it feels like this raises some standard, and clears something out.” Another strategy is to ask: if I had no choice but to bet $50,000 on whether or not my strategy will result in the observable outcome I say it will, what would I bet? This depends on your honest ability to put yourself in an imaginary situation, but I find it surprisingly effective. Prediction markets like [Polymarket](https://polymarket.com/) are becoming popular with altruists in part because they give you real-world practice with this mindset, with real-world results to learn from.

5.  **Dry vs visceral:** This pair should be especially salient for animal advocates. As with rote and new, it would be impossible for us to function if we were fully in touch with the magnitude of human atrocities against animals all the time. On the other hand, if our strategic arguments feel sterile or dry, something has probably gone terribly wrong. If we are arguing for one approach or another without ever viscerally feeling the tradeoffs each approach implies for animals trapped eternally in cages, we will find it all too easy to revert to undisciplined forms of thinking.


Carlsmith’s *fake* and *real thinking* has echoes in the notion of *system 1* and *system 2* thinking popularized by Daniel Kahneman in his book *Thinking, Fast and Slow.* System 1, the fast brain and the older one evolutionarily, uses familiar habits and simple heuristics for processing our environment. It’s the brain that allows us to jump up quickly when we hear a lion’s roar, rather than needing to take the time to reason through whether the sound should be cause for concern. We necessarily use system 1 for routine tasks in our day-to-day lives, and it takes conscious effort to turn on the slower, more recently evolved system 2. Major strategic questions are exactly the thing you should save it for.

## 3.2 The Disciplinary Canon

Within a few years of effective altruism taking a major role in the animal movement, animal activists were achieving bigger changes for more animals than they had in several previous decades all added up. That was possible thanks to the deep commitment to disciplined thinking demonstrated by EAs like Carlsmith and his colleagues at Open Philanthropy. Many people shaped the EA movement in this way, but one person who deserves particular credit for teaching “real thinking” is Eliezer Yudkowsky. Yudkowsky’s long-running blog on overcoming cognitive bias is an important part of the EA canon. Reading the early volumes of that blog, collectively known as *the sequences,* was a critical part of my own journey of realizing just how disorganized my own thinking had been. It was gruelling, like an open-heart epistemic surgery lasting hundreds of thousands of words. But it was well worth every moment. It made me look back on my first ~8 years of activism as largely time wasted.

If you have a sense that there may be elements of magical or undisciplined thinking still shaping your outlook on activism, and you really want to let them go, *[the sequences](https://www.readthesequences.com/)* are a worthy undertaking. There’s a [fantastic, free audio production](https://podcasts.apple.com/us/podcast/rationality-from-ai-to-zombies/id1299826696) that makes them more accessible. For now, here’s one of Eliezer’s mantras most relevant to our current topic:

**[Make your beliefs pay rent in anticipation](https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences).**

This relates closely to Carlsmith’s *hollow vs. solid*, wherein we notice that deep down we suspect that a certain belief we are conditioning on is actually bullshit*.* Yudkowsky’s point is this: *beliefs that do not predict observable events in the real world are not real beliefs*. Imagine a person who claims there is a dragon in their garage. When you ask to see it, they explain that it is an invisible dragon. When you ask to touch it, they explain it is ephemeral. They could just be lying, but we all know of another possibility: they sincerely *believe* they hold this belief, but on some level, they know better than to actually condition their expectations on it. This is the difference between *true belief,* and *belief in belief.* They don’t believe in the dragon, but they believe they believe it.

Something like this was happening with my belief in early DxE’s theory of change. I had a coherent explanation of how our strategy would work:

> *DxE uses eye-grabbing disruptions inside restaurants and grocery stores to shock the public out of their complacency with violence against animals. But the public isn’t the only target. Just as important is to radicalize vegans. We find people who are currently isolated, lonely, apologetic vegans, draw them into a supportive community, then inspire them to take socially transgressive actions together like disruptions and open rescues. These experiences transform them, making animal rights the most important part of their identity and giving them the confidence to speak out when they return to their existing communities. Social change will happen when we can create a critical mass of these individual evangelists, spreading the word at every holiday dinner table across the country.*

It sounds good, and there’s still part of me that stirs when I type it out. I’m not certain whether it is right or wrong. *But did I truly believe it?* If this theory were true, what consequences could we expect to see in the real world? If we had set up an empirical experiment to see whether it was true, would I really have expected to see it born out? Or would I have preemptively come up with some excuse for why that experiment wasn’t really measuring what mattered? Those are questions for me to reflect on; they’re about my state of mind, not about whether the theory of change had merit.

Beliefs take up precious space in your mind. When you’re deciding on an animal activism strategy, there’s only room for so many beliefs to play a role in the decision. Beliefs that are not shaping the observable consequences you expect from your actions don’t deserve to be kept around. Or as Eliezer says, “If a belief turns deadbeat, evict it.”

## 3.3 Laws vs. pathways: why empiricism is the only winning option for strategy

Bringing it back to empiricism, I want to share one more framing that helps me think about the strategic process.

DxE was not responsible for my undisciplined thinking, and growing disillusioned with elements of that strategy did not mean I was out of the woods. When I left, I knew I wanted to start my own grassroots organization that kept the parts I thought were right and fixed the parts I thought were wrong. My plan was to spend years designing everything about the organization: the strategy, the messaging, the structure and values. I thought I needed to get it all right before launching, because I’d seen how hard it was to rectify these issues in a decentralized organization once it was up and running.

I remember an argument with a friend who did not think this was the right approach. I explained myself by arguing that building a successful movement organization is like launching a rocket to the moon. Contrary to the phrase “shoot for the moon and you’ll reach the stars,” actually if you miss the moon you’ll just drift in the empty void forever. You’ve really got to be sure you’re going to hit the moon when you launch your rocket; you can’t redesign the rocket mid-flight.

My use of this metaphor illustrates exactly where my younger self had gone astray. First of all, rocket science is our culture’s go-to idiom for extremely hard things for exactly this reason. If there is any chance we could approach social change the way any other science works, that would definitely be preferable. Second, even rocket science is iterative! Rocket scientists don’t build a rocket by planning everything out on paper without testing anything. Their tests tend to be very expensive, which is precisely why it’s difficult, and precisely why we should try to emulate literally any other process if possible.

The problem was that I was thinking about social change strategy in terms of *laws.* I thought that, like the laws of physics, there were certain timeless principles underpinning social change that successful movements throughout history had tapped into. I thought DxE and the Save Movement were right to study past movements to try to deduce those laws and build a social movement strategy around them; if those groups weren’t succeeding, it was because there was some gap or error in their deduction.

This kind of thinking works well for physicists and mathematicians. A shocking amount of our understanding of the deep laws of physics came not through novel experimentation, but through geniuses like Einstein and Hawking sitting at their desks and directing uncompromising mental discipline at the problems before them. And pure math is called pure precisely because there is no possibility of experimentation; deduction is the only method available.

Why does logical deduction work for math and physics? Because, as it turns out, the laws governing math and physics are remarkably simple. Simple does not mean intuitive or easy for a human to grasp, as anyone taking their first class in quantum mechanics can assure you. But they are *simple.* The more we learn about the physical world, the fewer laws there turn out to be. In one generation, one physicist attempts to penetrate the mystery of the tides, while another experiments with falling objects. A generation later, a flash of insight reveals these seemingly unrelated phenomena to be governed by the same force, the same law: gravity. The philosopher of science Edward Newton (no relation) dubbed this process *conciliance*. Bit by bit, our understanding of the universe gets *simpler.* Einstein’s greatest contributions collapsed reality into even fewer laws, and he died seeking to collapse them further still.

Physical laws are exclusive. The law describes one way things work, at the exclusion of all the other ways they could work. Under specified conditions, an object of a certain mass will behave exactly one way. Say you are trying to fire a cannonball at a target, or land a rocket on the moon. Once you calculate the distance and the force of gravity, there is an exact amount of force you must apply to hit your target. No other amount will do. We should understand the word *law* as describing a *one-to-one relationship between an input and an output.* Physics and math are lawful domains because if you fire an identical cannonball in an identical way, it will land in the same place every time.

All other sciences are progressive abstractions built on top of physics.

![](https://substack-post-media.s3.amazonaws.com/public/images/ea543463-a960-473f-a5d5-524d70e50171_740x308.png)

Chemistry is a special case of physics involving molecules of more than one atom. Simple chemistry can still be described as having *laws,* though the number of variables you have to account for increases considerably. But by the time we reach organic chemistry, the special case of chemistry underpinning biology, we have already begun to exit the domain of law. In organic chemistry, there is more than one way to achieve the same outcome. DNA encodes instructions for building proteins using four nucleotides and just twenty amino acids. But evolution could have built a genetic code using different nucleotides, and there are hundreds of possible amino acids it could have used. The same protein can catalyze one reaction in one biological system but serve an entirely different function in another hypothetical organism. There isn’t one way to build life; countless biochemical pathways can achieve similar outcomes.

Continuing up the complexity ladder, psychology is a very special case of biology involving unusually complex brains. And sociology or economics are rare cases of psychology when millions of those brains interact. This is the level where we attempt to design social movement strategies. On this level, we have left the domain of laws so far behind that we might as well be on another planet. Nothing in the world of economics or sociology respects one-to-one relationships between inputs and outputs. If you try to recreate the same input into the system a second time, you can be absolutely certain the result will not be the same. The system will have changed too much, not least because in our case there are other people who are studying those past actions and trying to prevent you from succeeding in the same way. Describing anything as a *law of economics* or a *law of social movements* is a terrible abuse of the term, and puts us in a frame of mind that is doomed to fail.

Developing strategy requires a totally different way of thinking about the problem space. Rather than seeking to understand the laws and using them to calculate an action and its results, we must think in terms of *pathways* through a complex network or system. Picture yourself trying to fire a cannonball again, but instead of a straight line, the ball must wind its way through a three-dimensional labyrinth that is constantly reconfiguring itself in unpredictable ways, while your adversaries try to block it or steer it off course at every turn. There are almost an infinite number of pathways you could take through this sociological maze. A small fraction of them lead to the specific outcome you are targeting. That fraction of infinity still leaves countless possible winning strategies– though each of them will lead to additional outcomes both foreseeable and unforeseeable, desirable and undesirable.

What does it mean in practice to stop thinking in the domain of laws and think instead about pathways through a system? For one, we’d forget any metaphor about firing a rocket at the moon. We’d place much less value on big strategic ideas and much more on organizational agility, the ability to quickly change course in response to new information or shifts in our environment. Marshall Ganz, Hahrie Han, and other movement researchers call this *strategic capacity.*

The new generation of grassroots groups discussed in this essay all embody this shift from focusing on *brilliant strategy* to building the *strategic capacity* to adapt and respond quickly. For some reason, in my mind, the image this conjures instead of a rocket ship is a sailboat. Sailboat orgs differ from rocket orgs in three concrete ways. First, as I focused on so far, sailboat orgs are constantly reading their environment and making frequent small adjustments, and occasional large adjustments, rather than committing to long journeys without course corrections. When setting off on a sailboat, the initial bearing matters much less than your ability to collect and process navigational data.

Second, sailboat captains are obsessed with the quality of the crew. These organizations focus on building an outstanding team, elevating people according to meritocracy and their proven ability to deliver results. Experimenting outside the lines is rewarded, but so is reliably performing your role when the moment comes for the crew to execute a big maneuver in unison.

Third, sailboats require clearly-defined leadership who have enough legitimate authority to announce a change in direction without provoking a mutiny. If a rocket ship tries to steer too sharply, it will be torn in half by its own momentum. I saw this happen in DxE, and also in Extinction Rebellion, a climate protest group with a very similar origin story and theory of change. There came a time in both organizations where the leaders realized they were not on track to succeed. But both orgs had a decentralized, leaderless ethos. Members who were involved in the organization more casually saw these efforts to exercise badly needed strategic leadership as little more than a power grab, and revolted against it.

In summary, **stop trying to find the laws of social movements.** There are none. Instead, focus on building your organization’s capacity to find a pathway through an ever-evolving maze, via constant experimentation.

# Destination: Winning

Many of the debates I’ve touched on in this essay are not settled. Animal activists still disagree about the merits of cage-free campaigns, vegan outreach, and the blowback from ambitious strategies like Animal Rising’s campaign to block factory farms using permit objections. My thesis here was not meant to resolve any of those debates, at least not directly. The merits of these strategies ultimately won’t be determined through rational debate. Debate is a deductive process. The answers to these questions do not lie in your mind. They lie *out there!* On the open seas!

I wish I could tell you it was a beautiful day to set sail, that the skies were clear. But as you know, they are not. There are storms all around us. If it were easy, someone would have done it already. Instead, it will be Hard. But I believe in you. With quick but steady hands, we can find our way through this.

![](https://substack-post-media.s3.amazonaws.com/public/images/a6ace92d-c032-4606-a2a2-92a6d63c325a_1536x1024.png)

Sail on,

Sandcastles

**Mantras:**

-   **The future belongs to the empiricists.**

-   **Disciplined thinking is thinking that insists on achieving the goal.**

-   **Empirical learning is about shortening the loop between trial and feedback.**

-   **Even if you can’t collect quantitative data, an experimental, empirical attitude goes a long way.**

-   **Make your beliefs pay rent in anticipation.**

-   **Stop trying to find the laws of social movements. There are none.**


[^1]: What I’m calling the *logical* approach was known in ML as *symbolic,* because it focused on inscribing meaning into computer code through symbolic representation. What I’m calling *empirical* was usually called *statistical* because of an early recognition that inductive systems were most successful when correlations were expressed probabilistically. This is an important point in itself: symbolic approaches adopted the language of formal rules like “all trees are plants,” while statistical approaches treated the connection between “tree” and “plant” as a probability. We’d all do well to think of the world more often in terms of probabilities than hard rules.

[^2]: There was a third important piece of work happening during this time, which was the U.S. ballot initiatives against gestation crates led by HSUS. However, that was not convenient for my narrative so I left it out. I’m planning to publish a post about this history soon.
